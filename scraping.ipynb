{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentimen Analisis Review APK Play Store**\n",
        "\n",
        "- Nama : Tok Se Ka\n",
        "- ID :\n",
        "- Tipe Scraper : Play Store\n",
        "- Aplikasi Target : Youtube Kids"
      ],
      "metadata": {
        "id": "6pmpH9obb0NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "jZSDSMyeAFr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-play-scraper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGFzMazlFcE6",
        "outputId": "5c77a597-018d-4bb8-962a-e15cb74a17b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store.\n",
        "from google_play_scraper import app, reviews, Sort, reviews_all"
      ],
      "metadata": {
        "id": "GiYherKbOuQw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perintah di atas akan mengunduh dan menginstal pustaka google_play_scraper serta dependensinya jika diperlukan. Setelah instalasi selesai, Anda dapat mengimpor dan menggunakannya dalam notebook Anda untuk mengambil data dari Play Store dan melanjutkan dengan analisis sentimen."
      ],
      "metadata": {
        "id": "dEZsQeWkB9XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Pandas untuk manipulasi dan analisis data\n",
        "pd.options.mode.chained_assignment = None  # Menonaktifkan peringatan chaining\n",
        "import numpy as np  # NumPy untuk komputasi numerik\n",
        "seed = 0\n",
        "np.random.seed(seed)  # Mengatur seed untuk reproduktibilitas\n",
        "import matplotlib.pyplot as plt  # Matplotlib untuk visualisasi data\n",
        "import seaborn as sns  # Seaborn untuk visualisasi data statistik, mengatur gaya visualisasi\n",
        "\n",
        "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks\n",
        "\n",
        "!pip install sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-gVREDij2jV",
        "outputId": "f4d2c428-11f1-48a3-c178-4eeac6c41118"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stop words) dalam berbagai bahasa."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjct6DIjkHhE",
        "outputId": "baee378a-9ee4-4217-8f11-e4e950bab87f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scapping Dataset\n",
        "\n",
        "Pada proyek ini, kita akan melakukan analisis sentimen terhadap ulasan dan pendapat pengguna terkait aplikasi \"BY.U\" di Play Store. Analisis sentimen akan membantu kita untuk memahami bagaimana pengguna merasakan dan mengungkapkan pandangan mereka terhadap aplikasi ini.\n",
        "\n",
        "Dengan menggunakan berbagai teknik pemrosesan teks dan algoritma machine learning, kita akan mencoba mengidentifikasi apakah ulasan pengguna terhadap aplikasi \"BY.U\" cenderung positif, negatif, atau netral. Hasil analisis sentimen ini dapat memberikan wawasan berharga kepada pengembang aplikasi untuk meningkatkan pengalaman pengguna. Mari kita mulai menjelajahi ulasan pengguna dan menganalisis sentimen di sekitar aplikasi \"BY.U\" dengan lebih mendalam."
      ],
      "metadata": {
        "id": "FBMV4WK8cVA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store.\n",
        "from google_play_scraper import app, reviews_all, Sort\n",
        "\n",
        "# Mengambil semua ulasan dari aplikasi dengan ID 'com.byu.id' di Google Play Store.\n",
        "# Proses scraping mungkin memerlukan beberapa saat tergantung pada jumlah ulasan yang ada.\n",
        "scrapreview = reviews_all(\n",
        "    'com.google.android.apps.youtube.kids',          # ID aplikasi yt kids\n",
        "    lang='id',             # Bahasa ulasan (default: 'en')\n",
        "    country='id',          # Negara (default: 'us')\n",
        "    sort=Sort.MOST_RELEVANT, # Urutan ulasan (default: Sort.MOST_RELEVANT)\n",
        "    count=20000             # Jumlah maksimum ulasan yang ingin diambil\n",
        ")"
      ],
      "metadata": {
        "id": "GTy8liYBQD3p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan ulasan dalam file CSV\n",
        "import csv\n",
        "\n",
        "with open('ulasan_aplikasi.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review'])  # Menulis header kolom\n",
        "    for review in scrapreview:\n",
        "        writer.writerow([review['content']])  # Menulis konten ulasan ke dalam file CSV"
      ],
      "metadata": {
        "id": "S4oRwFULn9b8"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}